{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Clustering Stage\n",
    "This notebook contains the code to create the first stage in data clusterization. Here we deal with Spectral Clustering and Agglomerative Clustering in order to create labels of our data using the commands emulated by the cyberattackant. Metrics such as Davies-Bouldin Index and Calinski-Harabasz score are used to perform model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports \n",
    "\n",
    "# Utils functions\n",
    "from utils import *\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# ML imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "# Dimensionality reduction\n",
    "import umap\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "\n",
    "Clustering from a similarity matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity matrix\n",
    "Computation of cosine similarity matrix from a tf-idf vectorizer of the unique commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "df = pd.read_csv(\"../Data/Cluster_data.csv\")\n",
    "# Just take the commands feature\n",
    "df_commands = df[['_source.commands']]\n",
    "# Unique commands\n",
    "print('Number of unique commands in the dataset:', df_commands['_source.commands'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have to many unique commands, let us proceed with a \"command normalization\" to reduce the dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command normalization\n",
    "df_commands = command_normalization(df_commands)\n",
    "print('Number of unique commands in the processed dataset:', df_commands['_source.commands'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction of unique commands from 158436 to 3299. Let us proceed with the tf-idf vectorizer and the cosine similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the unique commands\n",
    "unique_commands = df_commands['_source.commands'].unique()\n",
    "\n",
    "# Create a TF-IDF vectorizer and compute the TF-IDF matrix for the unique commands\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(unique_commands)\n",
    "print('Tf-idf vectorization done!')\n",
    "\n",
    "# Compute the cosine similarity between the unique commands\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix,tfidf_matrix,dense_output=True)\n",
    "print('Similarity matrix computed!') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random walk normalized Laplacian. Optimal number of clusters\n",
    "This matrix will help us to choose the optimal number of clusters for the Spectral Clustering algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Laplacian\n",
    "L_rw = compute_Lrw(cosine_sim_matrix)\n",
    "\n",
    "# Calculate the eigenvalues of L_rw\n",
    "eigenvalues = np.linalg.eigvals(L_rw)\n",
    "\n",
    "# Sort the eigenvalues in ascending order\n",
    "sorted_eigenvalues = np.sort(eigenvalues)[:20]\n",
    "\n",
    "# Plot the first 20 eigenvalues\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_eigenvalues, marker='o', linestyle='')\n",
    "plt.xlabel(\"Eigenvalue Index\")\n",
    "plt.ylabel(\"Eigenvalues\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigengap heuristic. There first three eigenvalues are approximately 0. Then, there is a gap between the 3th and 4th eigenvalue, that is $|\\lambda_3 - \\lambda_4|$ is relatively large. According to the eigengap heuristic, this gap indicates that the data set contains 3 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering algorithm\n",
    "spectral_clustering = SpectralClustering(n_clusters=3, affinity='precomputed', random_state=42)\n",
    "spectral_labels = spectral_clustering.fit_predict(cosine_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the computed clusters to the whole dataframe\n",
    "\n",
    "# Create an empty dictionary for mapping\n",
    "commands_to_cluster = {}\n",
    "\n",
    "# Iterate through commands and cluster labels to create the mapping\n",
    "for command, cluster in zip(unique_commands, spectral_labels):\n",
    "    commands_to_cluster[command] = cluster\n",
    "\n",
    "# Mapping commands to each cluster\n",
    "def map_commands_to_cluster(command):\n",
    "    return commands_to_cluster.get(command, None)\n",
    "\n",
    "df['spectral_cluster'] = df_commands['_source.commands'].apply(map_commands_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering distribution for unique commands\n",
    "label_counts = Counter(spectral_labels)\n",
    "labels, counts = zip(*label_counts.items())\n",
    "\n",
    "# Increment each label by 1\n",
    "modified_labels = [label + 1 for label in labels]\n",
    "\n",
    "# Create a figure and axes for the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Customize the bar chart appearance\n",
    "ax.bar(modified_labels, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax.set_xlabel('Cluster', fontsize=10)\n",
    "ax.set_ylabel('Count', fontsize=10)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Set the x-ticks to show 1, 2, and 3\n",
    "ax.set_xticks([1, 2, 3])\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering distribution for the whole dataset\n",
    "label_counts = Counter(df['spectral_cluster'])\n",
    "labels, counts = zip(*label_counts.items())\n",
    "\n",
    "# Increment each label by 1\n",
    "modified_labels = [label + 1 for label in labels]\n",
    "\n",
    "# Create a figure and axes for the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Customize the bar chart appearance\n",
    "ax.bar(modified_labels, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax.set_xlabel('Cluster', fontsize=10)\n",
    "ax.set_ylabel('Count', fontsize=10)\n",
    "\n",
    "# Millions variable\n",
    "ax.set_yticklabels(['{:.0f}M'.format(y/ 1e6) for y in ax.get_yticks()])\n",
    "\n",
    "# Add grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "# Set the x-ticks to show only 1, 2, and 3\n",
    "ax.set_xticks([1, 2, 3])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP embedding\n",
    "reducer = umap.UMAP(metric='cosine', random_state=42)\n",
    "embedding = reducer.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Create a scatter plot with better aesthetics\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=spectral_labels, cmap='viridis', s=35, edgecolors='w', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=10)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=10)\n",
    "\n",
    "# Customize the grid and ticks\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatterplot\n",
    "reducer = umap.UMAP(metric='cosine',n_components=3, random_state = 42) \n",
    "embedding = reducer.fit_transform(tfidf_matrix) \n",
    "fig = px.scatter_3d(\n",
    "    embedding, x=0, y=1, z=2, color=spectral_labels, size=0.1*np.ones(len(unique_commands)), opacity = 1,\n",
    "    title='UMAP plot in 3D',\n",
    "    labels={'0': 'comp. 1', '1': 'comp. 2', '2': 'comp. 3'},\n",
    "    width=750, height=600,\n",
    "    color_continuous_scale = 'Viridis'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list, one per each cluster\n",
    "cluster_0 = []  \n",
    "cluster_1 = []  \n",
    "cluster_2 = []  \n",
    "\n",
    "for key, value in commands_to_cluster.items():\n",
    "    if value == 0:\n",
    "        cluster_0.append(key)\n",
    "    elif value == 1:\n",
    "        cluster_1.append(key)\n",
    "    else:\n",
    "        cluster_2.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Spectral cluster gives as a classification by threat levels.\n",
    "+ Cluster 0: Commands as uname, echo -e, etc -->display system information. Generally removing and creating new files. Scanning cluster.\n",
    "+ Cluster 1: Commands to start a terminal session, move and create files and sometimes download suspicious files to the system.\n",
    "+ Cluster 2: Commands to donwload and in most of the cases execute with permissions files (wget and chmod).\n",
    "\n",
    "These clusters monitor the threat levels as attackers infiltrate the targeted system. Cluster 0, categorized as level 1, poses the lowest threat, primarily performing system scans and extracting information. Cluster 1, designated as level 2, not only displays system information but may occasionally attempt to download files. Lastly, cluster 2, which corresponds to level 3, represents the highest threat level, consistently attempting to download and execute external files, potentially with malicious software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering\n",
    "Clustering from a similarity matrix. By the previous reasoning, 3 clusters seems a good approach. Let us taste it with another clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Agglomerative Clustering do not directly accept the similarity matrix as an input, but we can consider a distance matrix instead (dissimilarity matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative clustering with similarity matrix\n",
    "\n",
    "# Compute distance matrix\n",
    "distance_matrix = 1-cosine_sim_matrix\n",
    "\n",
    "# Create an AgglomerativeClustering model with three clusters(as before)\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3, linkage='complete', metric='precomputed')\n",
    "\n",
    "# Fit and predict the model with the distance matrix\n",
    "agg_clustering.fit(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering distribution for unique commands\n",
    "label_counts = Counter(agg_clustering.labels_)\n",
    "labels, counts = zip(*label_counts.items())\n",
    "\n",
    "# Increment each label by 1\n",
    "modified_labels = [label + 1 for label in labels]\n",
    "\n",
    "# Create a figure and axes for the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Customize the bar chart appearance\n",
    "ax.bar(modified_labels, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "ax.set_xlabel('Cluster', fontsize=10)\n",
    "ax.set_ylabel('Count', fontsize=10)\n",
    "\n",
    "# Add grid lines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "# Set the x-ticks to show only 1, 2, and 3\n",
    "ax.set_xticks([1, 2, 3])\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP embedding\n",
    "reducer = umap.UMAP(metric='cosine', random_state=42)\n",
    "embedding = reducer.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Create a scatter plot with better aesthetics\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=agg_clustering.labels_, cmap='viridis', s=35, edgecolors='w', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=10)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=10)\n",
    "\n",
    "# Customize the grid and ticks\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatterplot\n",
    "reducer = umap.UMAP(metric='cosine',n_components=3, random_state = 42) \n",
    "embedding = reducer.fit_transform(tfidf_matrix) \n",
    "fig = px.scatter_3d(\n",
    "    embedding, x=0, y=1, z=2, color=agg_clustering.labels_, size=0.1*np.ones(len(unique_commands)), opacity = 1,\n",
    "    title='UMAP plot in 3D',\n",
    "    labels={'0': 'comp. 1', '1': 'comp. 2', '2': 'comp. 3'},\n",
    "    width=650, height=500,\n",
    "    color_continuous_scale = 'Viridis'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just with the visualization one can observe that this model seems less consisting than the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "Use of Davies-Bouldin index and Calisnki-Harabasz index for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calinski-Harabasz index\n",
    "spectral_ch = calinski_harabasz_score(tfidf_matrix.toarray(),spectral_labels)\n",
    "agg_ch = calinski_harabasz_score(tfidf_matrix.toarray(),agg_clustering.labels_)\n",
    "\n",
    "# Davies-Bouldin index\n",
    "spectral_db = davies_bouldin_score(tfidf_matrix.toarray(),spectral_labels)\n",
    "agg_db = davies_bouldin_score(tfidf_matrix.toarray(),agg_clustering.labels_)\n",
    "\n",
    "# Create a table\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Metric\", \"Spectral Clustering\", \"Agglomerative Clustering\"]\n",
    "\n",
    "# Add your metrics to the table\n",
    "table.add_row([\"Calinski-Harabasz Score\", spectral_ch, agg_ch])\n",
    "table.add_row([\"Davies-Bouldin Index\", spectral_db, agg_db])\n",
    "\n",
    "# Print the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering shows better results!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe with labels\n",
    "df.to_csv(\"../Data/Cluster_data_wlabels.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
