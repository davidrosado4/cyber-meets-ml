{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting. LSTM approach.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this notebook, where we embark on an exploration of a Deep Learning approach to predict the number of cyberattacks a country may face in the following month. LSTM networks, a subtype of Recurrent Neural Networks (RNNs), excel in predicting future trends by efficiently capturing complex temporal patterns. Their distinctive architecture allows for the retention of critical information over time, enabling proactive identification of emerging patterns in sequential data. In this context, we leverage LSTM's capabilities to enhance our understanding and prediction of temporal dependencies, contributing to more effective forecasting measures\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Time Series Visualization\n",
    "\n",
    "2. Dataset Construction\n",
    "\n",
    "3. Sequencing for LSTM\n",
    "\n",
    "4. Train models\n",
    "\n",
    "5. Evaluation\n",
    "\n",
    "6. Bonus Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Visualization\n",
    "\n",
    "Let us read the data and visualize it as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df1 = pd.read_csv('../Data/21_november_to_april.csv')\n",
    "df2 = pd.read_csv('../Data/22_april_to_november.csv')\n",
    "df3 = pd.read_csv('../Data/22_november_to_april.csv')\n",
    "df4 = pd.read_csv('../Data/23_april_to_november.csv')\n",
    "\n",
    "# Concatenate dataframes\n",
    "df = pd.concat([df1, df2, df3, df4], axis=0, ignore_index=True)\n",
    "\n",
    "# Delete dataframes\n",
    "del  df1, df2, df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some countries to analyze\n",
    "df_Spain = select_country(df, 'Spain')\n",
    "df_USA = select_country(df, 'United States')\n",
    "df_Singapore = select_country(df, 'Singapore')\n",
    "df_Germany = select_country(df, 'Germany')\n",
    "df_Japan = select_country(df, 'Japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Spain = visualize_ts(df_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_USA = visualize_ts(df_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Singapore = visualize_ts(df_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Germany = visualize_ts(df_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Japan = visualize_ts(df_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction\n",
    "\n",
    "Let us generate features to forecast the number of cyberattacks a country might encounter in the future. We will begin by incorporating temporal elements such as the month, year, day, and so on. This will establish a baseline dataset for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline dataset. Just temporal information\n",
    "\n",
    "df_Spain = create_baseline_dataset(daily_count_Spain)\n",
    "df_USA = create_baseline_dataset(daily_count_USA)\n",
    "df_Singapore = create_baseline_dataset(daily_count_Singapore)\n",
    "df_Germany = create_baseline_dataset(daily_count_Germany)\n",
    "df_Japan = create_baseline_dataset(daily_count_Japan)\n",
    "\n",
    "# Visualize df_USA\n",
    "df_USA.head() # The first column is the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the ML_approach notebook, you can enhance the model by incorporating lagged features and rolling statistics features. We have a function in utils.py that divides the data into training, validation, and test sets while including the specified lagged and rolling statistics features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation and test sets with lagged and rolling features\n",
    "\n",
    "train_Spain, valid_Spain, test_Spain, scaler_Spain = create_features_lstm(df_Spain, 5,[2,3] )\n",
    "train_USA, valid_USA, test_USA, scaler_USA = create_features_lstm(df_USA, 1, [2,3,4,5])\n",
    "train_Singapore, valid_Singapore, test_Singapore, scaler_Singapore = create_features_lstm(df_Singapore, 4,[2,3,4] )\n",
    "train_Germany, valid_Germany, test_Germany, scaler_Germany = create_features_lstm(df_Germany, 5,[2,3,4,5] )\n",
    "train_Japan, valid_Japan, test_Japan, scaler_Japan = create_features_lstm(df_Japan,3 ,[2,3] )\n",
    "\n",
    "# Numbers of features\n",
    "num_feat_Spain = train_Spain.shape[1]\n",
    "num_feat_USA = train_USA.shape[1]\n",
    "num_feat_Singapore = train_Singapore.shape[1]\n",
    "num_feat_Germany = train_Germany.shape[1]\n",
    "num_feat_Japan = train_Japan.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing for LSTM \n",
    "\n",
    "Typically, the input data for an LSTM should be in the form of three-dimensional arrays, commonly known as tensors. The dimensions of these tensors represent the number of samples, the sequence length, and the number of features, respectively ([samples, timesteps, features]). For time series data, each sample corresponds to a different time point, and the sequence length determines how many previous time steps the model considers when making predictions This tensor is fed into the LSTM layer, enabling the model to learn temporal dependencies and patterns within the sequential data.\n",
    "\n",
    "In summary, organizing data for an LSTM involves structuring it into sequences, creating 3D tensors that encapsulate the temporal aspects of the data, and appropriately splitting the dataset for training and testing. This format facilitates the LSTM's ability to capture and learn from the sequential patterns within the input data.\n",
    "\n",
    "To achieve this, we have developed a class called WindowGenerator. This class is responsible for organizing the data into the specified tensor format, making it ready for training with LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate windows\n",
    "# Spain\n",
    "window_Spain = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_Spain,\n",
    "    val_df=valid_Spain,\n",
    "    test_df=test_Spain,\n",
    "    batch_size=1,\n",
    "    label_columns=['count'])\n",
    "\n",
    "# USA\n",
    "window_USA = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_USA,\n",
    "    val_df=valid_USA,\n",
    "    test_df=test_USA,\n",
    "    batch_size=4,\n",
    "    label_columns=['count'])\n",
    "\n",
    "# Singapore\n",
    "window_Singapore = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_Singapore,\n",
    "    val_df=valid_Singapore,\n",
    "    test_df=test_Singapore,\n",
    "    batch_size=1,\n",
    "    label_columns=['count'])\n",
    "\n",
    "# Germany\n",
    "window_Germany = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_Germany,\n",
    "    val_df=valid_Germany,\n",
    "    test_df=test_Germany,\n",
    "    batch_size=1,\n",
    "    label_columns=['count'])\n",
    "\n",
    "# Japan\n",
    "window_Japan = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_Japan,\n",
    "    val_df=valid_Japan,\n",
    "    test_df=test_Japan,\n",
    "    batch_size=1,\n",
    "    label_columns=['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models\n",
    "\n",
    "Let us create LSTM models for each individual country and proceed to train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "lstm_Spain = create_lstm(num_feat_Spain)\n",
    "lstm_USA = create_lstm(num_feat_USA)\n",
    "lstm_Singapore = create_lstm(num_feat_Singapore)\n",
    "lstm_Germany = create_lstm(num_feat_Germany)\n",
    "lstm_Japan = create_lstm(num_feat_Japan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "print('\\n\\n============= Spain =============\\n\\n')\n",
    "history_Spain = compile_and_fit_lstm(lstm_Spain, window_Spain, patience=5, MAX_EPOCHS=50)\n",
    "print('\\n\\n============= USA =============\\n\\n')\n",
    "history_USA = compile_and_fit_lstm(lstm_USA, window_USA, patience=5, MAX_EPOCHS=50)\n",
    "print('\\n\\n============= Singapore =============\\n\\n')\n",
    "history_Singapore = compile_and_fit_lstm(lstm_Singapore, window_Singapore, patience=5, MAX_EPOCHS=50)\n",
    "print('\\n\\n============= Germany =============\\n\\n')\n",
    "history_Germany = compile_and_fit_lstm(lstm_Germany, window_Germany, patience=5, MAX_EPOCHS=50)\n",
    "print('\\n\\n============= Japan =============\\n\\n')\n",
    "history_Japan = compile_and_fit_lstm(lstm_Japan, window_Japan, patience=5, MAX_EPOCHS=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Let us see the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "actual_train_Spain, pred_train_Spain, actual_test_Spain, pred_test_Spain = get_predictions_lstm(lstm_Spain,scaler_Spain, train_Spain,\n",
    "                                                                                                 test_Spain, window_Spain)\n",
    "actual_train_USA, pred_train_USA, actual_test_USA, pred_test_USA = get_predictions_lstm(lstm_USA,scaler_USA, train_USA,\n",
    "                                                                                                    test_USA, window_USA)\n",
    "actual_train_Singapore, pred_train_Singapore, actual_test_Singapore, pred_test_Singapore = get_predictions_lstm(lstm_Singapore,scaler_Singapore, train_Singapore,\n",
    "                                                                                                    test_Singapore, window_Singapore)\n",
    "actual_train_Germany, pred_train_Germany, actual_test_Germany, pred_test_Germany = get_predictions_lstm(lstm_Germany,scaler_Germany, train_Germany,\n",
    "                                                                                                    test_Germany, window_Germany)\n",
    "actual_train_Japan, pred_train_Japan, actual_test_Japan, pred_test_Japan = get_predictions_lstm(lstm_Japan,scaler_Japan, train_Japan,\n",
    "                                                                                                    test_Japan, window_Japan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for Spain\n",
    "plot_results_LSTM(actual_train_Spain, pred_train_Spain, actual_test_Spain, pred_test_Spain, test_Spain, train_Spain, scaler_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for USA\n",
    "plot_results_LSTM(actual_train_USA, pred_train_USA, actual_test_USA, pred_test_USA, test_USA, train_USA, scaler_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for Singapore\n",
    "plot_results_LSTM(actual_train_Singapore, pred_train_Singapore, actual_test_Singapore, pred_test_Singapore, test_Singapore, train_Singapore, scaler_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for Germany\n",
    "plot_results_LSTM(actual_train_Germany, pred_train_Germany, actual_test_Germany, pred_test_Germany, test_Germany, train_Germany, scaler_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for Japan\n",
    "plot_results_LSTM(actual_train_Japan, pred_train_Japan, actual_test_Japan, pred_test_Japan, test_Japan, train_Japan, scaler_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the metrics results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append predictions and actual values\n",
    "predictions = [pred_test_Spain.values, pred_test_USA.values, pred_test_Singapore.values, pred_test_Germany.values, pred_test_Japan.values]\n",
    "actual = [actual_test_Spain.values, actual_test_USA.values, actual_test_Singapore.values, actual_test_Germany.values, actual_test_Japan.values]\n",
    "countries = ['Spain', 'USA', 'Singapore', 'Germany', 'Japan']\n",
    "\n",
    "# Display results\n",
    "display_metrics_table(predictions, actual, countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Section\n",
    "\n",
    "Let us attempt to provide a European perspective. Is it possible to forecast the quantity of cyberattacks expected in Europe for the upcoming month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read European data and visualize it as a time series\n",
    "\n",
    "df_EU = select_continent(df, 'EU')\n",
    "\n",
    "daily_count_EU = visualize_ts(df_EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the baseline dataset\n",
    "df_EU = create_baseline_dataset(daily_count_EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation and test sets with lagged and rolling features\n",
    "train_EU, valid_EU, test_EU, scaler_EU = create_features_lstm(df_EU, 3, [2,3,4])\n",
    "\n",
    "# Numbers of features\n",
    "num_feat_EU = train_EU.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate windows\n",
    "\n",
    "window_EU = WindowGenerator(\n",
    "    input_width=3,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_EU,\n",
    "    val_df=valid_EU,\n",
    "    test_df=test_EU,\n",
    "    batch_size=1,\n",
    "    label_columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "lstm_EU = create_lstm(num_feat_EU)\n",
    "\n",
    "# Fit model\n",
    "print('\\n\\n============= EU =============\\n\\n')\n",
    "history_EU = compile_and_fit_lstm(lstm_EU, window_EU, patience=5, MAX_EPOCHS=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "actual_train_EU, pred_train_EU, actual_test_EU, pred_test_EU = get_predictions_lstm(lstm_EU,scaler_EU, train_EU,\n",
    "                                                                                                 test_EU, window_EU)\n",
    "\n",
    "# Plot predictions for EU\n",
    "plot_results_LSTM(actual_train_EU, pred_train_EU, actual_test_EU, pred_test_EU, test_EU, train_EU, scaler_EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
