{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting. Classical approach.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this notebook, where we embark on an exploration of two classical techniques, ARIMA (AutoRegressive Integrated Moving Average) and Prophet, to predict the number of cyberattacks a country may face in the following month.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Time Series Visualization\n",
    "\n",
    "2. Time Series Component Analysis\n",
    "    - 2.1 Trend\n",
    "    - 2.2 Seasonality\n",
    "    - 2.3 Stationarity\n",
    "\n",
    "3. ARIMA\n",
    "\n",
    "4. Prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requiered imports\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima.arima import auto_arima\n",
    "from prophet import Prophet\n",
    "from utils import *\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time Series Visualization <a class=\"anchor\" id=\"tsv\"></a>\n",
    "Let us read the data and visualize it as a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df1 = pd.read_csv('../Data/21_november_to_april.csv')\n",
    "df2 = pd.read_csv('../Data/22_april_to_november.csv')\n",
    "df3 = pd.read_csv('../Data/22_november_to_april.csv')\n",
    "df4 = pd.read_csv('../Data/23_april_to_november.csv')\n",
    "\n",
    "# Concatenate dataframes\n",
    "df = pd.concat([df1, df2, df3, df4], axis=0, ignore_index=True)\n",
    "\n",
    "# Delete dataframes\n",
    "del  df1, df2, df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some countries to analyze\n",
    "df_Spain = select_country(df, 'Spain')\n",
    "df_USA = select_country(df, 'United States')\n",
    "df_Singapore = select_country(df, 'Singapore')\n",
    "df_Germany = select_country(df, 'Germany')\n",
    "df_Japan = select_country(df, 'Japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Spain = visualize_ts(df_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_USA = visualize_ts(df_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Singapore = visualize_ts(df_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Germany = visualize_ts(df_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_Japan = visualize_ts(df_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Component Analysis\n",
    "\n",
    "Analyzing the components of a time series is a critical step that provides a wealth of valuable information before applying classical forecasting models. Each component, trend, seasonality, and noise, carries distinct insights, contributing to a comprehensive understanding that forms the basis for effective modeling. The components of a time series are:\n",
    "\n",
    "**Trend**: A gradual shift or movement to relatively higher or lower values over a long period of time.\n",
    " - When the time series analysis shows a general trend , that is upward . It is called uptrend.\n",
    " - When the time series analysis shows a general trend , that is downward. It is called downtrend.\n",
    " - When there is no trend, we call it horizontal or stationary trend.\n",
    "\n",
    "**Seasonality**: Patterns of variation that repeat at specific time intervals. These can be weekly, monthly, yearly, etc. Seasonal changes indicate deviations from the trend in specific directions.\n",
    "\n",
    "**Residuals**: Unusual events that occur in the data, such as a sudden increase in heart rate for a person during exercise. These cause random errors and are also referred to as “white noise.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend\n",
    "Used techniques to detect trends:\n",
    "\n",
    " - **Visual Inspection**: Plotting the time series data can often reveal the presence of a trend. A clear upward or downward movement over time suggests the presence of a trend component. Visual inspection allows you to observe the overall pattern and identify any deviations or changes in the series.\n",
    "\n",
    " - **Moving Averages**: Moving averages are widely used for trend analysis. They help smooth out short-term fluctuations in the data, making it easier to identify the underlying trend. Common types of moving averages include the simple moving average (SMA), weighted moving average (WMA), and exponential moving average (EMA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(daily_count_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(daily_count_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(daily_count_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(daily_count_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(daily_count_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the time series displays a distinct trend pattern, except for the United States, which shows a shy upward trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality\n",
    "\n",
    "Used techniques to detect seasonality:\n",
    "\n",
    "- **Autocorrelation Function (ACF) Plot**: The ACF plot shows the correlation between the time series and its lagged values. For a seasonal time series, the ACF plot often exhibits significant spikes at regular intervals, indicating the presence of seasonality.\n",
    "\n",
    "- **Seasonal Decomposition**: Seasonal decomposition of time series (STL) is a method that separates a time series into its individual components: trend, seasonality, and residual. This technique decomposes the series to better understand and analyze the seasonal component independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF & PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf('Spain', daily_count_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf('USA', daily_count_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf('Singapore', daily_count_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf('Germany', daily_count_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf('Japan', daily_count_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_ts(daily_count_Spain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_ts(daily_count_USA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_ts(daily_count_Singapore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_ts(daily_count_Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition_ts(daily_count_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Examining the ACF/PACF plots and decomposition plots, it is challenging to assert the presence of seasonality components in the time series. However, the USA appears to exhibit a subtle annual seasonality. \n",
    "\n",
    "Furthermore, it can be asserted that there is some white noise present, complicating the task of prediction. This complexity arises from the presence of peaks in cyberattacks that are challenging to explain solely by examining the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity\n",
    "\n",
    "A stationary time series is one whose statistical properties, such as mean and variance, remain constant over time. It implies that the series has a consistent behavior, and its patterns are predictable over different time periods. Let us implement the Dickey-Fuller Test to detect stationarity. Significance level $\\alpha = 0.5$. Hence, if $p$-value< $\\alpha$, we reject the null hypothesis.\n",
    "\n",
    " - **Null Hypothesis**: The series is non-stationary.\n",
    " - **Alternative Hypothesis**: The series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=================== Spain Information ==============\\n\\n')\n",
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(daily_count_Spain.values)\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)\n",
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(daily_count_USA.values)\n",
    "print('\\n\\n=================== USA Information ==============\\n\\n')\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)\n",
    "print('\\n\\n=================== Singapore Information ==============\\n\\n')\n",
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(daily_count_Singapore.values)\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)\n",
    "print('\\n\\n=================== Germany Information ==============\\n\\n')\n",
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(daily_count_Germany.values)\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)\n",
    "print('\\n\\n=================== Japan Information ==============\\n\\n')\n",
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(daily_count_Japan.values)\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting the Dickey-Fuller Test, it is evident that only the USA time series is non-stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "It is a class of models that captures different aspects of time series data, such as trend and seasonality. Here's a breakdown of the components of ARIMA:\n",
    "\n",
    " - **AutoRegressive (AR) component**: This part of the model represents the relationship between the current observation and its past observations. \n",
    "\n",
    " - **Integrated (I) component**: This component accounts for the differencing needed to make the time series stationary.\n",
    " \n",
    " - **Moving Average (MA) component**: This part of the model represents the relationship between the current observation and a residual error from a moving average model applied to lagged observations.\n",
    "\n",
    "With the exception of the United States, the others time series exhibit stationarity without requiring any differencing order. Let's determine the appropriate order of differencing for the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf, pval, usedlag, nobs, crit_vals, icbest =  adfuller(pd.DataFrame(daily_count_USA.diff().values).dropna())\n",
    "print('=================== USA Information ==============\\n\\n')\n",
    "print('ADF test statistic:', adf)\n",
    "print('ADF p-values:', pval)\n",
    "print('ADF number of lags used:', usedlag)\n",
    "print('ADF number of observations:', nobs)\n",
    "print('ADF critical values:', crit_vals)\n",
    "print('ADF best information criterion:', icbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series from USA is stationary with one order of differencing. Let us use autoARIMA, to find the optimal number of parameters for every time series ARIMA Models are specified by three order parameters: (p, d, q)\n",
    "\n",
    " - p is the order of the AR term. \n",
    "\n",
    " - q is the order of the MA term.\n",
    "\n",
    " - d is the number of differencing required to make the time series stationary.\n",
    "\n",
    "Before training the model, let us create a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_Spain, test_Spain = daily_count_Spain[:-30], daily_count_Spain[-30:]\n",
    "train_USA, test_USA = daily_count_USA[:-30], daily_count_USA[-30:]\n",
    "train_Singapore, test_Singapore = daily_count_Singapore[:-30], daily_count_Singapore[-30:]\n",
    "train_Germany, test_Germany = daily_count_Germany[:-30], daily_count_Germany[-30:]\n",
    "train_Japan, test_Japan = daily_count_Japan[:-30], daily_count_Japan[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spain training\n",
    "model_Spain = auto_arima(train_Spain, start_p=1, start_q=1,\n",
    "                      test='adf',\n",
    "                      max_p=6, max_q=6,\n",
    "                      m=1,             \n",
    "                      d=0,          \n",
    "                      seasonal=False, \n",
    "                      max_order=13,  \n",
    "                      D=None, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA training\n",
    "model_USA = auto_arima(train_USA, start_p=1, start_q=1,\n",
    "                      test='adf',\n",
    "                      max_p=6, max_q=6,\n",
    "                      m=1,             \n",
    "                      d=1,    \n",
    "                      max_order=13,      \n",
    "                      seasonal=False, \n",
    "                      D=None, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singapore training\n",
    "model_Singapore = auto_arima(train_Singapore, start_p=1, start_q=1,\n",
    "                      test='adf',\n",
    "                      max_p=6, max_q=6,\n",
    "                      m=1,             \n",
    "                      d=0,          \n",
    "                      seasonal=False, \n",
    "                      max_order=13,  \n",
    "                      D=None, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Germany training\n",
    "model_Germany = auto_arima(train_Germany, start_p=1, start_q=1,\n",
    "                      test='adf',\n",
    "                      max_p=6, max_q=6,\n",
    "                      m=1,             \n",
    "                      d=0,          \n",
    "                      seasonal=False, \n",
    "                      max_order=13,  \n",
    "                      D=None, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japan training\n",
    "model_Japan = auto_arima(train_Japan, start_p=1, start_q=1,\n",
    "                      test='adf',\n",
    "                      max_p=6, max_q=6,\n",
    "                      m=1,             \n",
    "                      d=0,          \n",
    "                      seasonal=False, \n",
    "                      max_order=13,  \n",
    "                      D=None, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us forecast a month and check the performance using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "prediction_Spain, confint_Spain = model_Spain.predict(n_periods=30, return_conf_int=True)\n",
    "prediction_USA, confint_USA = model_USA.predict(n_periods=30, return_conf_int=True)\n",
    "prediction_Singapore, confint_Singapore = model_Singapore.predict(n_periods=30, return_conf_int=True)\n",
    "prediction_Germany, confint_Germany = model_Germany.predict(n_periods=30, return_conf_int=True)\n",
    "prediction_Japan, confint_Japan = model_Japan.predict(n_periods=30, return_conf_int=True)\n",
    "\n",
    "# Store confidence interval\n",
    "cf_Spain= pd.DataFrame(confint_Spain)\n",
    "cf_USA= pd.DataFrame(confint_USA)\n",
    "cf_Singapore= pd.DataFrame(confint_Singapore)\n",
    "cf_Germany= pd.DataFrame(confint_Germany)\n",
    "cf_Japan= pd.DataFrame(confint_Japan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_classical_approach(prediction_Spain, cf_Spain, train_Spain, test_Spain, 'Spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_classical_approach(prediction_USA, cf_USA, train_USA, test_USA, 'USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_classical_approach(prediction_Singapore, cf_Singapore, train_Singapore, test_Singapore, 'Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_classical_approach(prediction_Germany, cf_Germany, train_Germany, test_Germany, 'Germany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_classical_approach(prediction_Japan, cf_Japan, train_Japan, test_Japan, 'Japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet\n",
    "Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\n",
    "\n",
    "The input of the model differs from ARIMA. Prophet needs the date in a column. Let us prepare the data for Prophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for prophet\n",
    "\n",
    "train_Spain_prophet = prophet_data_format(train_Spain)\n",
    "test_Spain_prophet = prophet_data_format(test_Spain)\n",
    "\n",
    "train_USA_prophet = prophet_data_format(train_USA)\n",
    "test_USA_prophet = prophet_data_format(test_USA)\n",
    "\n",
    "train_Singapore_prophet = prophet_data_format(train_Singapore)\n",
    "test_Singapore_prophet = prophet_data_format(test_Singapore)\n",
    "\n",
    "train_Germany_prophet = prophet_data_format(train_Germany)\n",
    "test_Germany_prophet = prophet_data_format(test_Germany)\n",
    "\n",
    "train_Japan_prophet = prophet_data_format(train_Japan)\n",
    "test_Japan_prophet = prophet_data_format(test_Japan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "model_Spain = Prophet()\n",
    "model_Spain.fit(train_Spain_prophet)\n",
    "prediction_Spain = model_Spain.predict(pd.DataFrame(test_Spain_prophet['ds']))\n",
    "\n",
    "model_USA = Prophet()\n",
    "model_USA.fit(train_USA_prophet)\n",
    "prediction_USA = model_USA.predict(pd.DataFrame(test_USA_prophet['ds']))\n",
    "\n",
    "model_Singapore = Prophet()\n",
    "model_Singapore.fit(train_Singapore_prophet)\n",
    "prediction_Singapore = model_Singapore.predict(pd.DataFrame(test_Singapore_prophet['ds']))\n",
    "\n",
    "model_Germany = Prophet()\n",
    "model_Germany.fit(train_Germany_prophet)\n",
    "prediction_Germany = model_Germany.predict(pd.DataFrame(test_Germany_prophet['ds']))\n",
    "\n",
    "model_Japan = Prophet()\n",
    "model_Japan.fit(train_Japan_prophet)\n",
    "prediction_Japan = model_Japan.predict(pd.DataFrame(test_Japan_prophet['ds']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Spain.plot(prediction_Spain)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_USA.plot(prediction_USA)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Singapore.plot(prediction_Singapore)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Germany.plot(prediction_Germany)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Japan.plot(prediction_Japan)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
